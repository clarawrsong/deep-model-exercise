{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import Dataset\n",
    "from skimage import io, transform\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_delta(df): \n",
    "    \"\"\"\n",
    "    adds column delta_w_z_right to df data\n",
    "    \"\"\"\n",
    "    delta_w_z_right_r_unit_v_col = []\n",
    "\n",
    "    for row in range(len(df)-1):    \n",
    "        curr_type = df.at[row, \"types_x\"]\n",
    "        next_type = df.at[row+1, \"types_x\"]\n",
    "\n",
    "        if curr_type == next_type: \n",
    "            curr_w_z_right = df.at[row, \"w_z_right_r_unit_v\"]\n",
    "            next_w_z_right = df.at[row+1, \"w_z_right_r_unit_v\"]\n",
    "            delta = next_w_z_right - curr_w_z_right\n",
    "        else: #CHANGE\n",
    "            curr_w_z_right = df.at[row, \"w_z_right_r_unit_v\"]\n",
    "            prev_w_z_right = df.at[row-1, \"w_z_right_r_unit_v\"]\n",
    "            delta = curr_w_z_right - prev_w_z_right\n",
    "            \n",
    "        delta_w_z_right_r_unit_v_col += [delta]\n",
    "\n",
    "    last_w_z_right = df_video.at[len(df)-1, \"w_z_right_r_unit_v\"]\n",
    "    prev_w_z_right = df_video.at[len(df)-2, \"w_z_right_r_unit_v\"]\n",
    "    delta = curr_w_z_right - prev_w_z_right\n",
    "    delta_w_z_right_r_unit_v_col += [delta]    \n",
    "\n",
    "    delta_w_z_right_r_unit_v_col = np.array(delta_w_z_right_r_unit_v_col).reshape(-1, 1)\n",
    "\n",
    "    df[\"delta_w_z_right\"] = delta_w_z_right_r_unit_v_col * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15726\n",
      "15726\n",
      "Index(['types_x', 'e_x_right_r', 'e_y_right_r', 'e_z_right_r', 'w_x_right_r',\n",
      "       'w_y_right_r', 'w_z_right_r', 's_x_right_r', 's_y_right_r',\n",
      "       's_z_right_r', 'c_x_right_r', 'c_y_right_r', 'c_z_right_r',\n",
      "       's_x_left_r', 's_y_left_r', 's_z_left_r', 'e_x_left_r', 'e_y_left_r',\n",
      "       'e_z_left_r', 'w_x_left_r', 'w_y_left_r', 'w_z_left_r',\n",
      "       'e_x_right_r_unit_v', 'e_y_right_r_unit_v', 'e_z_right_r_unit_v',\n",
      "       'w_x_right_r_unit_v', 'w_y_right_r_unit_v', 'w_z_right_r_unit_v',\n",
      "       'delta_w_z_right'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "remove_cols = [\n",
    "       'Unnamed: 0', 'index', 'e_x_right', 'e_y_right', 'e_z_right',\n",
    "       'w_x_right', 'w_y_right', 'w_z_right', 's_x_right', 's_y_right',\n",
    "       's_z_right', 'c_x_right', 'c_y_right', 'c_z_right', 's_x_left',\n",
    "       's_y_left', 's_z_left', 'e_x_left', 'e_y_left', 'e_z_left', 'w_x_left',\n",
    "       'w_y_left', 'w_z_left', 'types_y', 'v_types', \"trial\",\n",
    "              \n",
    "#        'e_x_right_r', 'e_y_right_r', 'e_z_right_r', 'w_x_right_r',\n",
    "#        'w_y_right_r', 'w_z_right_r', 's_x_right_r', 's_y_right_r',\n",
    "#        's_z_right_r', 'c_x_right_r', 'c_y_right_r', 'c_z_right_r',\n",
    "#        's_x_left_r', 's_y_left_r', 's_z_left_r', 'e_x_left_r', 'e_y_left_r',\n",
    "#        'e_z_left_r', 'w_x_left_r', 'w_y_left_r', 'w_z_left_r',\n",
    "]\n",
    "\n",
    "df_video = pd.read_csv(\"./data/video_all_data.csv\")\n",
    "df_video = df_video.drop(columns=remove_cols)\n",
    "add_delta(df_video)\n",
    "\n",
    "print(len(df_video))\n",
    "\n",
    "X_train, X_test = train_test_split(df_video,test_size=0.8)\n",
    "\n",
    "print(len(X_train) + len(X_test))\n",
    "\n",
    "X_train.to_csv(r'./data/test2_video.csv')\n",
    "X_test.to_csv(r'./data/train2_video.csv')\n",
    "\n",
    "print(df_video.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'e_x_right', 'e_y_right', 'e_z_right', 'index',\n",
      "       'move_type', 'p_num', 's_types', 's_x_right', 's_y_right', 's_z_right',\n",
      "       'time', 'trial', 'trial_extra', 'types', 'w_x_right', 'w_y_right',\n",
      "       'w_z_right', 'e_x_right_r_unit_v', 'e_y_right_r_unit_v',\n",
      "       'e_z_right_r_unit_v', 'w_x_right_r_unit_v', 'w_y_right_r_unit_v',\n",
      "       'w_z_right_r_unit_v'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_sensor = pd.read_csv(\"./data/sensor_all_data.csv\")\n",
    "print(df_sensor.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FramesDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.frames = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        data = self.frames.iloc[idx, :]    \n",
    "        exc_type = int(data['types_x'][-2:])-1   # NOTICE: exc01 is at index 0\n",
    "        data = torch.tensor(data[2:])\n",
    "                \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        return data, exc_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = FramesDataset(csv_file = 'data/train2_video.csv', root_dir='data/')\n",
    "test = FramesDataset(csv_file = 'data/test2_video.csv', root_dir='data/')\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=5, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data in enumerate(trainset, 0):\n",
    "#     x, y = data\n",
    "#     print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  \n",
    "        self.fc1 = nn.Linear(28, 120) #no 2 with 64\n",
    "#         self.fc2 = nn.Linear(120, 64)\n",
    "        self.fc3 = nn.Linear(120, 15)\n",
    "    \n",
    "        # ADD weights for delta HERE\n",
    "        # nn.Parameter\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)   # taking log_softmax not needed? for optimization?\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm for first-order gradient-based optimization, built into PyTorch.\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 1.347\n",
      "[1,  2000] loss: 0.752\n",
      "[2,  1000] loss: 0.484\n",
      "[2,  2000] loss: 0.399\n",
      "[3,  1000] loss: 0.295\n",
      "[3,  2000] loss: 0.280\n",
      "[4,  1000] loss: 0.223\n",
      "[4,  2000] loss: 0.205\n",
      "[5,  1000] loss: 0.178\n",
      "[5,  2000] loss: 0.181\n",
      "[6,  1000] loss: 0.162\n",
      "[6,  2000] loss: 0.147\n",
      "[7,  1000] loss: 0.145\n",
      "[7,  2000] loss: 0.128\n",
      "[8,  1000] loss: 0.111\n",
      "[8,  2000] loss: 0.125\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 8\n",
    "\n",
    "for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainset, 0):\n",
    "        # get the inputs; data is dictionary\n",
    "        X, y = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = net(X)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.961\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X)\n",
    "        for index, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[index]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EPOCHS = 3\n",
    "<br>\n",
    "(28,120) -> (120,15)<br>\n",
    "0.926, 0.914, 0.92 <br>\n",
    "vs. 0.928, 0.906, 0.91<br>\n",
    "vs. 0.893 <br>\n",
    "vs. .911<br>\n",
    "\n",
    "delta * 100<br>\n",
    "vs. delta * 10 <br>\n",
    "vs. delta <br>\n",
    "vs. no delta<br>\n",
    "<br>\n",
    "<br>\n",
    "EPOCHS = 8<br>\n",
    "(28,120) -> (120,15)<br>\n",
    "0.952, 0.961<br>\n",
    "vs. 0.936, 0.943<br>\n",
    "\n",
    "delta * 10<br>\n",
    "vs. no delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD Make seed_pytorch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
