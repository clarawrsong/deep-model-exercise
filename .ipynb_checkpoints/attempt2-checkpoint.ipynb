{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from skimage import io, transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_delta(df): \n",
    "    \"\"\"\n",
    "    adds column delta_w_z_right to df data\n",
    "    \"\"\"\n",
    "    delta_w_z_right_r_unit_v_col = []\n",
    "\n",
    "    for row in range(len(df)-1):    \n",
    "        curr_type = df.at[row, \"types_x\"]\n",
    "        next_type = df.at[row+1, \"types_x\"]\n",
    "\n",
    "        if curr_type == next_type: \n",
    "            curr_w_z_right = df.at[row, \"w_z_right_r_unit_v\"]\n",
    "            next_w_z_right = df.at[row+1, \"w_z_right_r_unit_v\"]\n",
    "            delta = next_w_z_right - curr_w_z_right\n",
    "        else: #CHANGE\n",
    "            curr_w_z_right = df.at[row, \"w_z_right_r_unit_v\"]\n",
    "            prev_w_z_right = df.at[row-1, \"w_z_right_r_unit_v\"]\n",
    "            delta = curr_w_z_right - prev_w_z_right\n",
    "            \n",
    "        delta_w_z_right_r_unit_v_col += [delta]\n",
    "\n",
    "    last_w_z_right = df_video.at[len(df)-1, \"w_z_right_r_unit_v\"]\n",
    "    prev_w_z_right = df_video.at[len(df)-2, \"w_z_right_r_unit_v\"]\n",
    "    delta = curr_w_z_right - prev_w_z_right\n",
    "    delta_w_z_right_r_unit_v_col += [delta]    \n",
    "\n",
    "    delta_w_z_right_r_unit_v_col = np.array(delta_w_z_right_r_unit_v_col).reshape(-1, 1)\n",
    "    \n",
    "    df[\"delta_w_z_right\"] = delta_w_z_right_r_unit_v_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15726\n",
      "15726\n"
     ]
    }
   ],
   "source": [
    "remove_cols = ['Unnamed: 0', 'index', 'e_x_right', 'e_y_right', 'e_z_right',\n",
    "       'w_x_right', 'w_y_right', 'w_z_right', 's_x_right', 's_y_right',\n",
    "       's_z_right', 'c_x_right', 'c_y_right', 'c_z_right', 's_x_left',\n",
    "       's_y_left', 's_z_left', 'e_x_left', 'e_y_left', 'e_z_left', 'w_x_left',\n",
    "       'w_y_left', 'w_z_left', 'types_y', 'v_types', \"trial\"]\n",
    "\n",
    "df_video = pd.read_csv(\"./data/video_all_data.csv\")\n",
    "df_video = df_video.drop(columns=remove_cols)\n",
    "add_delta(df_video)\n",
    "\n",
    "print(len(df_video))\n",
    "\n",
    "X_train, X_test = train_test_split(df_video,test_size=0.8)\n",
    "\n",
    "print(len(X_train) + len(X_test))\n",
    "\n",
    "X_train.to_csv(r'./data/test2_video.csv')\n",
    "X_test.to_csv(r'./data/train2_video.csv')\n",
    "\n",
    "# print(df_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class FramesDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.frames = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.frames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        data = self.frames.iloc[idx, :]    \n",
    "        exc_type = int(data['types_x'][-2:])-1   # NOTICE: exc01 is at index 0\n",
    "        data = torch.tensor(data[2:])\n",
    "                \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        return data, exc_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = FramesDataset(csv_file = 'data/train2_video.csv', root_dir='data/')\n",
    "test = FramesDataset(csv_file = 'data/test2_video.csv', root_dir='data/')\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=5, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, data in enumerate(trainset, 0):\n",
    "#     x, y = data\n",
    "#     print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28, 120) #no 2 with 64\n",
    "#         self.fc2 = nn.Linear(120, 64)\n",
    "        self.fc3 = nn.Linear(120, 15)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)   # taking log_softmax not needed? for optimization?\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# algorithm for first-order gradient-based optimization, built into PyTorch.\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)  \n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 1.404\n",
      "[1,  2000] loss: 0.807\n",
      "[2,  1000] loss: 0.554\n",
      "[2,  2000] loss: 0.461\n",
      "[3,  1000] loss: 0.368\n",
      "[3,  2000] loss: 0.348\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainset, 0):\n",
    "        # get the inputs; data is dictionary\n",
    "        X, y = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        output = net(X)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.893\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X)\n",
    "        for index, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[index]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(28,64) -> (64,48) -> (48,15)\\n0.879\\n\\n(28,120) -> (120,15)\\n0.904\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "(28,64) -> (64,48) -> (48,15)\n",
    "0.879\n",
    "\n",
    "(28,120) -> (120,15)\n",
    "0.893\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
